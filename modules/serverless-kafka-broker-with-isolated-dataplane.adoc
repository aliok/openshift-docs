// Module included in the following assemblies:
//
// * serverless/develop/serverless-using-brokers.adoc

:_content-type: PROCEDURE
[id="serverless-kafka-broker-with-isolated-dataplane_{context}"]
= Creating a Kafka broker that uses an isolated data plane

Knative Kafka Broker implementation has 2 planes: control plane and data plane. Control plane consists of controllers that talk to Kubernetes API, watch for custom objects and manage the data plane.

Data plane is the collection of components that listen for incoming events, talk to Apache Kafka and also sends events to the event sinks. This is where the events flow. Knative Kafka Broker data plane consists of `kafka-broker-receiver` and `kafka-broker-dispatcher` deployments.

When using the Broker class `Kafka`, the Knative Kafka Broker uses a shared data plane. That means, `kafka-broker-receiver` and `kafka-broker-dispatcher` deployments in `knative-eventing` namespace is used for all Kafka Brokers in the cluster.

However, when `KafkaNamespaced` is set as the Broker class, Kafka broker controller creates a new data plane for each namespace that there is a broker exists. This data plane is used by all `KafkaNamespaced` brokers in that namespace.

That provides isolation between the data planes, which means that the `kafka-broker-receiver` and `kafka-broker-dispatcher` deployments in the user namespace are only used for the broker in that namespace.

[IMPORTANT]
====
As a consequence of separate data planes, this security feature creates more deployments and uses more resources. Unless you have such isolation requirements, it is recommended to go with *regular* Broker with `Kafka` class.
====

To create a `KafkaNamespaced` broker, you must set the `eventing.knative.dev/broker.class` annotation to `KafkaNamespaced`.

.Prerequisites

* The {ServerlessOperatorName}, Knative Eventing, and the `KnativeKafka` custom resource are installed on your {product-title} cluster.

* You have access to a Kafka instance such as link:https://access.redhat.com/documentation/en-us/red_hat_amq/7.6/html/amq_streams_on_openshift_overview/kafka-concepts_str#kafka-concepts-key_str[Red Hat AMQ Streams], and have created a Kafka topic.

* You have created a project or have access to a project with the appropriate roles and permissions to create applications and other workloads in {product-title}.

* You have installed the OpenShift CLI (`oc`).

.Procedure

. Create a Kafka-based broker as a YAML file:
+
[source,yaml]
----
apiVersion: eventing.knative.dev/v1
kind: Broker
metadata:
  annotations:
    eventing.knative.dev/broker.class: KafkaNamespaced <1>
  name: default
  namespace: my-namespace <2>
spec:
  config:
    apiVersion: v1
    kind: ConfigMap
    name: my-config <2>
    # namespace: my-namespace <3>
...
----
<1> The broker class. To use the Kafka broker with isolated data planes, this value must be `KafkaNamespaced`.
<2> The referenced configmap `my-config` must be in the same namespace with the `Broker` object, in this case `my-namespace`
<3> No need to define the configmap's namespace as it defaults to Broker's namespace

. Apply the Kafka-based broker YAML file:
+
[source,terminal]
----
$ oc apply -f <filename>
----

[IMPORTANT]
====
The configmap that is specified in `spec.config` **must** be in the same namespace with the `Broker` object:

[source,yaml]
----
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-config
  namespace: my-namespace
data:
  ...
----
====

Upon the creation of the first `Broker` with `KafkaNamespaced` class, the `kafka-broker-receiver` and `kafka-broker-dispatcher` deployments are created in the namespace. After that, all the brokers with `KafkaNamespaced` class in the same namespace use the same data plane. When there are no brokers of `KafkaNamespaced` class in the namespace, the data plane in the namespace will be deleted.
